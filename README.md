# âœ¨ Chatterbox TTS

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyPI](https://img.shields.io/badge/PyPI-chatterbox--tts-green.svg)](https://pypi.org/project/chatterbox-tts/)
[![GitHub Stars](https://img.shields.io/github/stars/resemble-ai/chatterbox.svg?style=social)](https://github.com/resemble-ai/chatterbox)
[![Discord](https://img.shields.io/badge/Discord-Join%20us-7289DA.svg)](https://discord.gg/rJq9cRJBJ6)

> **State-of-the-art, open-source Text-to-Speech models by Resemble AI**

ğŸš€ High-quality speech synthesis with ultra-low latency. Perfect for voice agents, narration, and creative workflows.

---

## ğŸŒŸ Overview

**Chatterbox** is a family of cutting-edge, open-source TTS models designed for modern AI applications. The flagship **Chatterbox-Turbo** model delivers exceptional speech quality with minimal computational requirementsâ€”powered by a streamlined 350M parameter architecture.

This fork adds **production-ready tools** for real-world use:
- ğŸ™ï¸ **Reader Bot** â€” Select any text, press a hotkey, hear it spoken instantly
- ğŸ¤– **Agent REPL** â€” Interactive command-line TTS with voice switching
- âš¡ **Optimized Async Streaming** â€” GPU-accelerated, non-blocking audio pipeline

### Why Chatterbox?

âœ… **Production-Ready** â€” Sub-200ms latency for real-time voice agents  
âœ… **Efficient** â€” 350M parameters, lower VRAM requirements  
âœ… **Expressive** â€” Native support for paralinguistic tags ([laugh], [cough], etc.)  
âœ… **Multilingual** â€” 23+ languages supported  
âœ… **Zero-Shot Voice Cloning** â€” Generate voices without fine-tuning  
âœ… **Open Source** â€” MIT Licensed, fully customizable  
âœ… **Watermarked** â€” Built-in responsible AI watermarking  

---

## âš¡ Model Zoo

| Model | Size | Languages | Key Features | Best For |
|-------|------|-----------|--------------|----------|
| **Chatterbox-Turbo** | 350M | English | Paralinguistic tags, Lower compute | Voice agents, Production |
| **Chatterbox-Multilingual** | 500M | 23+ | Zero-shot cloning | Global apps, Localization |
| **Chatterbox** | 500M | English | CFG & Exaggeration tuning | Creative control, General use |

---

## ğŸš€ Quick Start Tools

### ğŸ“– Reader Bot (Select & Speak)

**The fastest way to hear any text on your screen.**

1. Run the bot:
   ```bash
   run_bot.bat
   ```

2. Wait for: `"Reader bot is ready"` (audio confirmation)

3. **Usage:**
   - Select any text on your screen
   - Press `Ctrl + Alt + R` â†’ Instant TTS playback
   - Press `Ctrl + Alt + X` â†’ Stop playback immediately
   - Press `Ctrl + C` â†’ Exit the bot

**Features:**
- âš¡ Async streaming (audio starts before full generation completes)
- ğŸ¯ Smart text chunking for instant response
- ğŸ›‘ Immediate stop on hotkey
- ğŸ”Š Optimized precision: Transformer (FP16) + Vocoder (FP32)

---

### ğŸ¤– Agent REPL (Interactive CLI)

**A conversational TTS agent with voice switching.**

```bash
python run_agent.py
```

**Commands:**
| Command | Action |
|---------|--------|
| `Type any text` | Generate and play TTS |
| `reload_voice` | Switch to custom voice (`male_voice.wav`) |
| `reset_voice` | Revert to default female voice |
| `exit` | Quit the agent |

**Custom Voice:**
- Drop a `male_voice.wav` file in the project root
- Type `reload_voice` to activate it
- Must be 5+ seconds of clean speech

---

## ğŸ“¦ Installation

### Prerequisites

- **Python 3.10** (required for PyTorch CUDA compatibility)
- **NVIDIA GPU** with CUDA support (RTX 4050+ recommended)
- **Windows 10/11** (for `run_bot.bat`)

### Quick Setup

```bash
# Clone the repo
git clone https://github.com/Lucky0nly/Chatter_box.git
cd Chatter_box

# Create virtual environment
python -m venv venv_py310
venv_py310\Scripts\activate

# Install dependencies
pip install -e .
pip install keyboard pyperclip sounddevice

# Install PyTorch with CUDA
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Alternative: Automated Setup

```bash
setup_and_run.bat
```

---

## ğŸ¯ Code Examples

### Chatterbox-Turbo (Programmatic)

```python
import torchaudio as ta
from chatterbox.tts_turbo import ChatterboxTurboTTS

# Load the model
model = ChatterboxTurboTTS.from_pretrained(device="cuda")

# Generate with paralinguistic tags
text = "Hi there, Sarah calling back [chuckle], have you got a minute?"
wav = model.generate(
    text,
    audio_prompt_path="reference_clip.wav"
)

# Save output
ta.save("output.wav", wav, model.sr)
```

### Multilingual Support

```python
from chatterbox.mtl_tts import ChatterboxMultilingualTTS

model = ChatterboxMultilingualTTS.from_pretrained(device="cuda")

# French
wav_fr = model.generate(
    "Bonjour, comment Ã§a va?",
    language_id="fr"
)

# Chinese
wav_zh = model.generate(
    "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”çœŸä¸é”™",
    language_id="zh"
)
```

More examples in `example_tts.py`, `example_vc.py`, and `example_tts_turbo.py`.

---

## ğŸ“‚ Project Structure

```
chatterbox/
â”œâ”€â”€ src/chatterbox/
â”‚   â”œâ”€â”€ tts_turbo.py          # Turbo model implementation
â”‚   â”œâ”€â”€ tts.py                # Standard TTS model
â”‚   â”œâ”€â”€ mtl_tts.py            # Multilingual model
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ t3/               # Transformer backbone
â”‚       â””â”€â”€ s3gen/            # Vocoder
â”œâ”€â”€ reader_bot.py             # ğŸ†• Async streaming TTS bot
â”œâ”€â”€ run_bot.bat               # ğŸ†• Windows launcher for Reader Bot
â”œâ”€â”€ run_agent.py              # ğŸ†• Interactive REPL agent
â”œâ”€â”€ setup_and_run.bat         # ğŸ†• Automated setup script
â”œâ”€â”€ gradio_tts_app.py         # Gradio web UI
â”œâ”€â”€ gradio_tts_turbo_app.py   # Turbo Gradio app
â”œâ”€â”€ multilingual_app.py       # Multilingual demo app
â”œâ”€â”€ pyproject.toml            # Dependencies
â”œâ”€â”€ LICENSE                   # MIT License
â””â”€â”€ README.md                 # This file
```

---

## âš™ï¸ Performance Optimization

### GPU Precision Settings

The Reader Bot uses optimized mixed-precision for best speed/quality balance:

| Component | Precision | Reason |
|-----------|-----------|--------|
| Transformer (T3) | FP16 | 2x faster inference |
| Vocoder (S3Gen) | FP32 | Stable audio quality |

This is configured automatically in `reader_bot.py`:

```python
model.t3 = model.t3.to("cuda").half()       # Speed
model.s3gen = model.s3gen.to("cuda").float() # Quality
```

### Latency Expectations

| Text Length | Generation Time | Notes |
|-------------|-----------------|-------|
| ~50 chars | ~1-2s | Single chunk |
| ~200 chars | ~4-6s | Multiple chunks, streaming |
| ~500 chars | ~8-12s | Long form, fully streamed |

*Tested on RTX 4050 6GB*

---

## ğŸ—£ï¸ Supported Languages

Arabic â€¢ Danish â€¢ German â€¢ Greek â€¢ English â€¢ Spanish â€¢ Finnish â€¢ French â€¢ Hebrew â€¢ Hindi â€¢ Italian â€¢ Japanese â€¢ Korean â€¢ Malay â€¢ Dutch â€¢ Norwegian â€¢ Polish â€¢ Portuguese â€¢ Russian â€¢ Swedish â€¢ Swahili â€¢ Turkish â€¢ Chinese

---

## ğŸ’¡ Pro Tips

### Configuration Best Practices

**General Use:**
- Default settings (`exaggeration=0.5`, `cfg_weight=0.5`) work well for most cases
- Ensure reference clip language matches the target language
- Set `cfg_weight=0` to ignore reference speaker characteristics

**Fast Speakers:**
- Lower `cfg_weight` to ~0.3 to improve pacing

**Expressive Speech:**
- Try lower `cfg_weight` (~0.3) with higher `exaggeration` (0.7+)
- Note: Higher exaggeration speeds up speech; reduce `cfg_weight` to compensate

---

## ğŸ›¡ï¸ Built-in Responsible AI Watermarking

Every generated audio includes **Resemble AI's Perth Watermarker**â€”imperceptible neural watermarks that survive compression and editing while maintaining 100% detection accuracy.

### Watermark Detection

```python
import perth
import librosa

audio, sr = librosa.load("generated_audio.wav", sr=None)
watermarker = perth.PerthImplicitWatermarker()
watermark = watermarker.get_watermark(audio, sample_rate=sr)

print(f"Watermark detected: {watermark}")  # 0.0 (no) or 1.0 (yes)
```

---

## ğŸš€ Roadmap

- [x] Chatterbox-Turbo (350M) release
- [x] Multilingual support (23+ languages)
- [x] Paralinguistic tag support
- [x] Zero-shot voice cloning
- [x] **Real-time streaming (Reader Bot)**
- [x] **Async pipeline optimization**
- [x] **Hotkey controls**
- [ ] Fine-tuning toolkit
- [ ] Multi-speaker models
- [ ] Emotion control features

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Contributing & Community

**Issues & Discussions:** [GitHub Issues](https://github.com/resemble-ai/chatterbox/issues)  
**Discord Community:** [Join our Discord](https://discord.gg/rJq9cRJBJ6)  
**Twitter:** [@ResembleAI](https://twitter.com/resembleai)

---

## ğŸ™ Acknowledgments

Built with inspiration from:
- [Cosyvoice](https://github.com/FunAudioLLM/CosyVoice)
- [Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)
- [HiFi-GAN](https://github.com/yl4579/HiFTNet)
- [Llama 3](https://github.com/meta-llama/llama3)
- [S3Tokenizer](https://github.com/xingchensong/S3Tokenizer)

---

## ğŸ“š Citation

If you use Chatterbox in your research, please cite:

```bibtex
@misc{chatterboxtts2025,
  author       = {{Resemble AI}},
  title        = {{Chatterbox-TTS: State-of-the-art Open-source Text-to-Speech}},
  year         = {2025},
  howpublished = {\url{https://github.com/resemble-ai/chatterbox}},
  note         = {GitHub repository}
}
```

---

## âš ï¸ Disclaimer

Use Chatterbox responsibly. Do not use for:
- Impersonation or fraud
- Spreading misinformation
- Creating non-consensual deepfakes
- Violating privacy laws

---

<div align="center">

**Made with â¤ï¸ by [Resemble AI](https://resemble.ai)**

[ğŸŒ Website](https://resemble.ai) Â· [ğŸ™ï¸ Demo](https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo) Â· [ğŸ“– Docs](https://github.com/resemble-ai/chatterbox) Â· [ğŸ’¬ Discord](https://discord.gg/rJq9cRJBJ6)

</div>
